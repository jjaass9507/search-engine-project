# è³‡è¨Šæª¢ç´¢ (IR) æœŸæœ«å°ˆæ¡ˆ - è¿·ä½ æœå°‹å¼•æ“
# (Information Retrieval Term Project - Mini Search Engine)

é€™æ˜¯ä¸€å€‹ç‚ºã€Œè³‡è¨Šæª¢ç´¢èˆ‡ç”Ÿæˆå¼AI (Information Retrieval and Generative Artificial Intelligence)ã€èª²ç¨‹æ‰€æ‰“é€ çš„å°å‹ç¶²é æœå°‹å¼•æ“ã€‚

æœ¬å°ˆæ¡ˆä¸åƒ…å¯¦ä½œäº†åŸºç¤çš„æœå°‹å¼•æ“æµç¨‹ï¼Œé‚„åŒ…å«äº†**æœå°‹å“è³ªè©•ä¼° (Precision@5)** ä»¥åŠ **ç‰‡èªæœå°‹ (Bigrams)** ç­‰é€²éšåŠŸèƒ½ã€‚

**Demo:**
*(å»ºè­°ä¸Šå‚³ä¸€å¼µç¶²é æˆªåœ–å–ä»£æ­¤è¡Œ)*

---

## ğŸš€ å°ˆæ¡ˆç‰¹è‰² (Features)

### æ ¸å¿ƒåŠŸèƒ½
1.  **(A) ç¶²é çˆ¬èŸ² (`crawler.py`):**
    * ä½¿ç”¨ `requests` + `BeautifulSoup4`ã€‚
    * **ç¦®è²Œçˆ¬å–**ï¼šéµå¾ª `robots.txt` è¦ç¯„åŠ 2 ç§’å»¶é² (`CRAWL_DELAY`)ã€‚
    * ç›®æ¨™çˆ¬å– 1,000 é ç‰¹å®šä¸»é¡Œ (å¦‚ AI/Tech) ç¶²é ã€‚
2.  **(B) ç´¢å¼•å»ºç«‹ (`indexer.py`):**
    * ä½¿ç”¨ `scikit-learn` çš„ `TfidfVectorizer`ã€‚
    * **é€²éšæ–‡å­—è™•ç†**ï¼šåŒ…å«è‹±æ–‡åœç”¨è©ç§»é™¤ã€å‹•æ…‹ `max_df`/`min_df` é–¾å€¼èª¿æ•´ã€‚
    * å°‡æ¨¡å‹åºåˆ—åŒ–å„²å­˜ç‚º `.joblib` æª”ï¼Œç¢ºä¿æœå°‹æ•ˆç‡ã€‚
3.  **(C) æœå°‹èˆ‡æ’åº (`search_logic.py`):**
    * ä½¿ç”¨ **é¤˜å¼¦ç›¸ä¼¼åº¦ (Cosine Similarity)** é€²è¡Œæ’åºã€‚
    * æ”¯æ´é¡¯ç¤ºæœå°‹çµæœæ‘˜è¦ (Snippet) èˆ‡ç›¸é—œæ€§åˆ†æ•¸ã€‚
4.  **(D) ç¶²é ä»‹é¢ (`app.py`):**
    * åŸºæ–¼ **Flask** çš„è¼•é‡ç´š Web Appã€‚
    * åŒ…å«é¦–é ã€çµæœé ã€é—œæ–¼é é¢ã€‚

### ğŸ† åŠ åˆ†åŠŸèƒ½ (Bonus Features)
* **æœå°‹å“è³ªè©•ä¼°å·¥å…· (`evaluate.py`):**
    * å¯¦ä½œ **Precision@5** è©•ä¼°æŒ‡æ¨™ã€‚
    * æä¾›äº’å‹•å¼ä»‹é¢ï¼Œè®“ä½¿ç”¨è€…æ‰‹å‹•æ¨™è¨»æœå°‹çµæœç›¸é—œæ€§ï¼Œä¸¦è¨ˆç®—å¹³å‡æº–ç¢ºç‡ (MAP)ã€‚
* **æ”¯æ´ç‰‡èªæœå°‹ (Phrase Search Support):**
    * åœ¨ç´¢å¼•éšæ®µå•Ÿç”¨ `ngram_range=(1, 2)`ã€‚
    * é™¤äº†å–®å­— (Unigrams) å¤–ï¼Œä¹Ÿèƒ½ç´¢å¼•é›™å­—ç‰‡èª (Bigrams)ï¼Œæå‡æœå°‹ "Artificial Intelligence" ç­‰å°ˆæœ‰åè©çš„ç²¾ç¢ºåº¦ã€‚
* **æœå°‹æ•ˆèƒ½é¡¯ç¤º:**
    * åœ¨æœå°‹çµæœé å³æ™‚é¡¯ç¤ºæŸ¥è©¢è€—æ™‚ (æ¯«ç§’)ã€‚

---

## ğŸ›  æŠ€è¡“æ£§ (Tech Stack)

* **Language:** Python 3.x
* **Web Framework:** Flask
* **IR / ML Libraries:** scikit-learn, numpy, scipy
* **Crawling:** requests, beautifulsoup4
* **Utilities:** joblib (æ¨¡å‹å„²å­˜), jieba (ä¸­æ–‡æ–·è©æ”¯æ´ - é¸ç”¨)

---

## ğŸ’» å¦‚ä½•åŸ·è¡Œ (How to Run)

### 1. ç’°å¢ƒè¨­å®š

```bash
# 1. ä¸‹è¼‰å°ˆæ¡ˆ
git clone [ä½ çš„ GitHub Repo URL]
cd ir_project

# 2. å»ºç«‹ä¸¦å•Ÿå‹•è™›æ“¬ç’°å¢ƒ
python -m venv venv
# Windows:
.\venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# 3. å®‰è£ä¾è³´
pip install -r requirements.txt
2. åŸ·è¡Œç®¡ç·š (Pipeline)
è«‹ä¾åºåŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿä¾†å•Ÿå‹•ç³»çµ±ï¼š

æ­¥é©Ÿä¸€ï¼šè³‡æ–™çˆ¬å–

Bash

python crawler.py
ç”¢å‡ºï¼šcrawled_data.json

æ­¥é©ŸäºŒï¼šå»ºç«‹ç´¢å¼•

Bash

python indexer.py
ç”¢å‡ºï¼štfidf_matrix.joblib, tfidf_vectorizer.joblib, metadata.json

æ­¥é©Ÿä¸‰ï¼šå•Ÿå‹•æœå°‹å¼•æ“

Bash

python app.py
å‰å¾€ç€è¦½å™¨æ‰“é–‹ http://127.0.0.1:5000 é–‹å§‹æœå°‹ï¼

3. åŸ·è¡Œè©•ä¼° (Bonus)
å¦‚æœä½ æƒ³æ¸¬è©¦æœå°‹å¼•æ“çš„æº–ç¢ºåº¦ï¼š

Bash

python evaluate.py
ç¨‹å¼æœƒè‡ªå‹•åŸ·è¡Œé è¨­çš„ 5-10 å€‹æŸ¥è©¢ã€‚

è«‹ä¾ç…§æç¤ºè¼¸å…¥ y (ç›¸é—œ) æˆ– n (ä¸ç›¸é—œ)ã€‚

æœ€å¾Œå°‡é¡¯ç¤º å¹³å‡ Precision@5 åˆ†æ•¸ã€‚

ğŸ“‚ æª”æ¡ˆçµæ§‹
Plaintext

ir_project/
â”‚
â”œâ”€â”€ .gitignore           # Git å¿½ç•¥è¨­å®š
â”œâ”€â”€ README.md            # å°ˆæ¡ˆæ–‡ä»¶
â”œâ”€â”€ requirements.txt     # å¥—ä»¶ä¾è³´æ¸…å–®
â”‚
â”œâ”€â”€ crawler.py           # (A) çˆ¬èŸ²ç¨‹å¼
â”œâ”€â”€ indexer.py           # (B) ç´¢å¼•ç¨‹å¼ (å« Bigram è¨­å®š)
â”œâ”€â”€ search_logic.py      # (C) æœå°‹é‚è¼¯æ ¸å¿ƒ
â”œâ”€â”€ app.py               # (D) Flask ç¶²é ä¸»ç¨‹å¼
â”œâ”€â”€ evaluate.py          # (Bonus) Precision@5 è©•ä¼°å·¥å…·
â”‚
â”œâ”€â”€ templates/           # ç¶²é æ¨¡æ¿
â”‚   â”œâ”€â”€ index.html       # æœå°‹é¦–é 
â”‚   â”œâ”€â”€ results.html     # çµæœé  (å«æ™‚é–“é¡¯ç¤º)
â”‚   â””â”€â”€ about.html       # é—œæ–¼é é¢
â”‚
â””â”€â”€ (è‡ªå‹•ç”Ÿæˆæª”æ¡ˆ - ä¸ä¸Šå‚³ GitHub)
    â”œâ”€â”€ crawled_data.json
    â”œâ”€â”€ metadata.json
    â”œâ”€â”€ *.joblib
    â””â”€â”€ venv/
